{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "\n",
    "https://github.com/SamKirkiles/vgg-cifar100\n",
    "\n",
    "https://github.com/geifmany/cifar-vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# from keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import models, layers\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置\n",
    "batch_size = 500\n",
    "num_classes = 100\n",
    "epochs = 700\n",
    "data_augmentation = False\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据\n",
    "# (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "from six.moves import cPickle\n",
    "def load_cifar100_my(path):\n",
    "    with open(os.path.join(os.getcwd(),path), 'rb') as f:\n",
    "        d = cPickle.load(f, encoding='bytes')\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode('utf8')] = v\n",
    "            d = d_decoded\n",
    "        data = d['data']\n",
    "        labels = d['fine_labels']\n",
    "        data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "        data = data.transpose(0,2,3,1)\n",
    "    return data, labels\n",
    "x_train, y_train = load_cifar100_my(r'data\\cifar-100-python\\train')\n",
    "x_test , y_test  = load_cifar100_my(r'data\\cifar-100-python\\test')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 数据预处理\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# x_train = x_train.astype('float16')\n",
    "# x_test  = x_test.astype('float16')\n",
    "# y_train = y_train.astype('float16')\n",
    "# y_test  = y_test.astype('float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train.dtype)\n",
    "print(x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(x_train[101])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape=x_train.shape[1:], name='inputs')\n",
    "# x = Conv2D(32, (3,3), padding='same', activation='relu')(inputs)\n",
    "# x = Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "# x = MaxPooling2D((2,2))(x)\n",
    "# x = Dropout(0.25, seed=42)(x)\n",
    "# x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "# x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "# x = MaxPooling2D((2,2))(x)\n",
    "# x = Dropout(0.25, seed=42)(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = Dropout(0.5, seed=42)(x)\n",
    "# # x = keras.layers.Add()([x,x])\n",
    "# prediction = Dense(num_classes, activation='softmax')(x)\n",
    "# model = Model(inputs=inputs, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = layers.Input(shape=x_train.shape[1:], name='inputs')\n",
    "# Block 1\n",
    "# Layer1 - 64 channels\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer2 - 64 channels\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Block 2\n",
    "# Layer 3 - 128 channels\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 4 - 128 channels\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Block 3\n",
    "# Layer 5 - 256 channels\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 6 - 256 channels\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 7 - 256 channels\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Block 4\n",
    "# Layer 8 - 512 channels\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 9 - 512 channels\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 10 - 512 channels\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Block 5\n",
    "# Layer 11 - 512 channels\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 12 - 512 channels\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "# Layer 13 - 512 channels\n",
    "x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = models.Model(img_input, x, name='vgg16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss and metrics\n",
    "# 如果是多分类多标签呢？\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, optimizer, metrics\n",
    "\n",
    "loss       = tensorflow.keras.losses.categorical_crossentropy\n",
    "# loss       = tensorflow.keras.losses.mean_squared_error\n",
    "\n",
    "# optimizer  = tensorflow.keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "optimizer  = tensorflow.keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "metrics    = [tensorflow.keras.metrics.categorical_accuracy]\n",
    "# metrics    = [tensorflow.keras.metrics.categorical_accuracy, tensorflow.keras.metrics.mae]\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_record = model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(x_test, y_test),\n",
    "                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9c8195fbb47d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_record_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'saved_models/model_fit_history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_record_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_record_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_record' is not defined"
     ]
    }
   ],
   "source": [
    "# 保存训练记录\n",
    "import pickle\n",
    "model_record_path = os.path.join(os.getcwd(), 'saved_models/model_fit_history')\n",
    "with open(model_record_path, 'wb') as f:\n",
    "    pickle.dump(model_record.history, f)\n",
    "with open(model_record_path, 'rb') as f:\n",
    "    print(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a3159e7a836c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_record' is not defined"
     ]
    }
   ],
   "source": [
    "model_record.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-967a6db35af2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_record\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_record' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(model_record.history['loss'],'r')\n",
    "plt.plot(model_record.history['val_loss'],'g')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(model_record.history['categorical_accuracy'],'r')\n",
    "plt.plot(model_record.history['val_categorical_accuracy'],'g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存路径设置\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'vgg16_keras_cifar100.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取模型\n",
    "# model = keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.shape for i in model.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所有的模型都可调用，就像网络层一样所有的模型都可调用，就像网络层一样\n",
    "\n",
    "利用函数式 API，可以轻易地重用训练好的模型，在调用模型时，您不仅重用模型的结构，还重用了它的权重。\n",
    "这种方式能允许我们快速创建可以处理序列输入的模型。只需一行代码，你就将图像分类模型转换为视频分类模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-83470cfa3e2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 之前定义的模型的输出是一个 10-way softmax，\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 因而下面的层的输出将是维度为 10 的 20 个向量的序列。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprocessed_sequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# 输入张量是 20 个时间步的序列，每一个时间为一个 784 维的向量\n",
    "input_sequences = Input(shape=(20, 784))\n",
    "\n",
    "# 这部分将我们之前定义的模型应用于输入序列中的每个时间步。\n",
    "# 之前定义的模型的输出是一个 10-way softmax，\n",
    "# 因而下面的层的输出将是维度为 10 的 20 个向量的序列。\n",
    "processed_sequences = TimeDistributed(model)(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多输入多输出模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to d:\\sync-cs\\bluoveGitHub\\note-on-ai\\pytorch-helloworld\\data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100\n",
       "    Number of datapoints: 50000\n",
       "    Split: train\n",
       "    Root Location: d:\\sync-cs\\bluoveGitHub\\note-on-ai\\pytorch-helloworld\\data\n",
       "    Transforms (if any): None\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.datasets.CIFAR100(r'd:\\sync-cs\\bluoveGitHub\\note-on-ai\\pytorch-helloworld\\data', train=True, transform=None, target_transform=None, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
